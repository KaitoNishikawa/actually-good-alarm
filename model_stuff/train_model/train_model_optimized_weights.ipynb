{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1bbd7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import joblib\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier, \n",
    "    ExtraTreesClassifier,\n",
    "    AdaBoostClassifier,\n",
    "    GradientBoostingClassifier,\n",
    ")\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b5aa707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "psg_label\n",
       "2    11203\n",
       "5     5030\n",
       "3     3252\n",
       "0     1907\n",
       "1     1475\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/train/bigboy_with_hr_mean.csv\")\n",
    "x = df[['cosine_feature', 'count_feature', 'hr_std', 'hr_mean', 'time_feature']]\n",
    "y = df['psg_label']\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b56b3e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.replace({5: 4}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f4a84b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18293, 5) (4574, 5) (18293,) (4574,)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20f546a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest        | 0.7608\n",
      "Saved Random Forest to ../saved_models/optimized_weights\\Random_Forest.joblib\n",
      "Extra Trees          | 0.7178\n",
      "Saved Extra Trees to ../saved_models/optimized_weights\\Extra_Trees.joblib\n",
      "Gradient Boosting    | 0.6530\n",
      "Saved Gradient Boosting to ../saved_models/optimized_weights\\Gradient_Boosting.joblib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kaito\\Desktop\\actually-good-alarm\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression  | 0.5564\n",
      "Saved Logistic Regression to ../saved_models/optimized_weights\\Logistic_Regression.joblib\n",
      "K-Nearest Neighbors  | 0.7595\n",
      "Saved K-Nearest Neighbors to ../saved_models/optimized_weights\\K-Nearest_Neighbors.joblib\n",
      "Neural Network       | 0.6544\n",
      "Saved Neural Network to ../saved_models/optimized_weights\\Neural_Network.joblib\n",
      "XGBoost              | 0.7713\n",
      "Saved XGBoost to ../saved_models/optimized_weights\\XGBoost.joblib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kaito\\Desktop\\actually-good-alarm\\venv\\Lib\\site-packages\\xgboost\\core.py:774: UserWarning: [03:25:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:62: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  return func(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "models_dir = \"../saved_models/optimized_weights\"\n",
    "\n",
    "class_weights = {\n",
    "    0: 1,  # Wake\n",
    "    1: 5,  # N1\n",
    "    2: 1,  # N2\n",
    "    3: 1,  # N3 (Deep Sleep) - Make this \"heavier\" so the model is scared to misclassify it\n",
    "    4: 1   # REM\n",
    "}\n",
    "\n",
    "algorithms = {\n",
    "    'Random Forest': RandomForestClassifier(class_weight=class_weights, n_estimators=200, min_samples_leaf=5),\n",
    "    'Extra Trees': ExtraTreesClassifier(class_weight=class_weights, n_estimators=200, min_samples_leaf=5),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(),\n",
    "    'Logistic Regression': LogisticRegression(class_weight=class_weights),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(),\n",
    "    'Neural Network': MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=1000),\n",
    "    'XGBoost': XGBClassifier(device='cuda')\n",
    "}\n",
    "\n",
    "for name, clf in algorithms.items():\n",
    "    clf.fit(x_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(x_test)\n",
    "    exact_score = clf.score(x_test, y_test)\n",
    "    print(f\"{name:<20} | {exact_score:.4f}\")    \n",
    "    # print(f\"{name}: {clf.features_}\")\n",
    "    # print(f\"{name}: {clf.feature_importances_}\")\n",
    "\n",
    "    model_filename = os.path.join(models_dir, f\"{name.replace(' ', '_')}.joblib\")\n",
    "    joblib.dump(clf, model_filename)\n",
    "    print(f\"Saved {name} to {model_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbef57cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
